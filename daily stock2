#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
PROGRAM: Stock Rec Date Check
VERSION: 1.2.0 (flagless)

Synopsis
--------
Validates that two daily inputs (Excel: "STOCK HOLDING.xlsx"; CSV: "Reconciliation - All Entities.csv")
refer to the same 'Statement Date'. If they agree, optionally saves both to a UNC directory with
date-stamped filenames and appends an audit row. If they mismatch or are stale (File 1 behind File 2
by > N business days), writes an audit row and exits non-zero. Missing or parse errors also exit non-zero.

What changed vs prior builds
----------------------------
- All file flag logic removed (no .flag files created, cleaned, or referenced).
- Console output + audit CSV + optional alerts are the only signals.

Exit codes
----------
0 = success (dates agree; UNC saves attempted; skip if already exists)
3 = stale or mismatch
2 = error (missing or read/parse error)

Platform assumptions
--------------------
- Windows workstation/server for Outlook COM (if used).
- Paths/UNCs accessible to the running account.
"""

from __future__ import annotations

import csv
import datetime as dt
import re
import sys
from pathlib import Path
from shutil import copy2

# ------------------- PROGRAM METADATA -------------------
PROGRAM_NAME = "Stock Rec Date Check"
VERSION = "1.2.0"

# ------------------- COLOR / UX HELPERS ----------------
# Uses colorama if present; otherwise prints plain text.
try:
    from colorama import init as _colorama_init, Fore, Style
    _colorama_init(autoreset=True)
    C_OK = Fore.GREEN + Style.BRIGHT
    C_WARN = Fore.YELLOW + Style.BRIGHT
    C_ERR = Fore.RED + Style.BRIGHT
    C_INFO = Fore.CYAN + Style.BRIGHT
    C_ALERT = Fore.MAGENTA + Style.BRIGHT
    C_DIM = Style.DIM
    C_RESET = Style.RESET_ALL
except Exception:
    class _NoColor:
        def __getattr__(self, _): return ""
    Fore = Style = _NoColor()
    C_OK = C_WARN = C_ERR = C_INFO = C_ALERT = C_DIM = C_RESET = ""

def banner():
    print(f"{C_INFO}{PROGRAM_NAME} v{VERSION}{C_RESET}")

def say_ok(msg: str):    print(f"{C_OK}‚úÖ {msg}{C_RESET}")
def say_warn(msg: str):  print(f"{C_WARN}‚ö†Ô∏è  {msg}{C_RESET}")
def say_err(msg: str):   print(f"{C_ERR}‚ùó {msg}{C_RESET}")
def say_info(msg: str):  print(f"{C_INFO}‚ÑπÔ∏è  {msg}{C_RESET}")
def say_alert(msg: str): print(f"{C_ALERT}üì£ {msg}{C_RESET}")
def say_step(msg: str):  print(f"{C_DIM}‚Üí {msg}{C_RESET}")

# ------------------- INPUT PATHS -------------------
STOCK_HOLDING_PATH = r"O:\Daily Stock Rec\Inbound\STOCK HOLDING.xlsx"                # File 1
RECON_ALL_ENTITIES_PATH = r"O:\Daily Stock Rec\Inbound\Reconciliation - All Entities.csv"  # File 2

# ------------------- AUDIT ----------------
AUDIT_LOG_PATH = r"O:\Daily Stock Rec\Audit\stock_rec_date_check_audit.csv"

# ------------------- UNC OUTPUT -------------------
UNC_BASE = r"\\icap.com\icaproot\Global\EMEA\UK\Department\UK Operations\Operational Services\Recs\Daily Stock Holding"
SAVE_ON_AGREE = True
SAVE_ON_MISMATCH = False         # If True, quarantine mismatches in a subfolder for investigation
QUARANTINE_SUBFOLDER = "__Mismatches"

# ------------------- STALE THRESHOLD --------------
# Mon‚ÄìFri only. Bank holidays ignored by design.
MAX_FILE1_AGE_BUSINESS_DAYS = 2

# ------------------- ALERTING (optional) ----------
USE_TEAMS_ALERT = False
TEAMS_WEBHOOK_URL = ""  # e.g., https://<org>.webhook.office.com/webhookb2/...

USE_OUTLOOK_EMAIL_ALERT = False
EMAIL_TO = "mirecsbelfast@tpicap.com"
EMAIL_SUBJECT = "[Alert] Stock Rec issue"

# ------------------- OUTLOOK FALLBACK -------------
ENABLE_OUTLOOK_FALLBACK_FILE1 = True
ENABLE_OUTLOOK_FALLBACK_FILE2 = True

OUTLOOK_FOLDER_FILE1 = r"MMcCullagh@tpicap.com\Inbox\DAILY STOCK"
OUTLOOK_FOLDER_FILE2 = r"MMcCullagh@tpicap.com\Inbox\DAILY STOCK"

OUTLOOK_SUBJECT_CONTAINS_FILE1 = "@Stock Holding"
OUTLOOK_SUBJECT_CONTAINS_FILE2 = "@Stock Rec All Entities EOD/"

ATTACH_NAME_CONTAINS_FILE1 = "Stock Holding"                  # .xlsx
ATTACH_NAME_CONTAINS_FILE2 = "Reconciliation - All Entities"  # .csv

OUTLOOK_SEARCH_WINDOW_DAYS = 10

# -------------- Patterns & helpers ----------------
MONTH_ABBR = ["", "Jan", "Feb", "Mar", "Apr", "May", "Jun",
              "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
WEEKDAY_ABBR = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]

RE_DD_MMM_YYYY = re.compile(r"\b(0[1-9]|[12]\d|3[01])-[A-Za-z]{3}-\d{4}\b")
RE_DD_MM_YYYY  = re.compile(r"\b(0[1-9]|[12]\d|3[01])/(0[1-9]|1[0-2])/\d{4}\b")

# ------------------- Generic utilities -------------------
def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)

def parse_date_token(token: str):
    if not token:
        return None
    s = str(token).strip()

    m = RE_DD_MMM_YYYY.search(s)
    if m:
        try:
            return dt.datetime.strptime(m.group(0), "%d-%b-%Y").date()
        except ValueError:
            pass
    m = RE_DD_MM_YYYY.search(s)
    if m:
        try:
            return dt.datetime.strptime(m.group(0), "%d/%m/%Y").date()
        except ValueError:
            pass

    for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%d %b %Y", "%d %B %Y", "%d-%B-%Y"):
        try:
            return dt.datetime.strptime(s, fmt).date()
        except ValueError:
            pass
    return None

def normalize_yyyy_mmm_dd(d: dt.date) -> str:
    return f"{d.year}-{MONTH_ABBR[d.month]}-{d.day:02d}"

def build_unc_target(base: str, d: dt.date) -> Path:
    year_folder = f"{d.year}"
    month_folder = f"{d.year}-{d.month:02d} {MONTH_ABBR[d.month]}"
    day_folder = f"{d.year}-{d.month:02d}-{d.day:02d} {WEEKDAY_ABBR[d.weekday()]}"
    return Path(base) / year_folder / month_folder / day_folder

def preferred_base_name(src: Path) -> str:
    name = src.name.lower()
    if name == "stock holding.xlsx":
        return "Stock Holding"
    if name == "reconciliation - all entities.csv":
        return "Reconciliation - All Entities"
    return src.stem

def dated_filename(src: Path, d: dt.date) -> str:
    base = preferred_base_name(src)
    day = f"{d.year}-{d.month:02d}-{d.day:02d} {WEEKDAY_ABBR[d.weekday()]}"
    return f"{base} {day}{src.suffix}"

def copy_if_absent(src: Path, dest: Path) -> bool:
    if dest.exists():
        say_warn(f"Skipped (already exists): {dest}")
        return False
    copy2(src, dest)
    say_ok(f"Saved: {dest}")
    return True

def business_days_between(d1: dt.date, d2: dt.date) -> int:
    if d1 == d2:
        return 0
    start, end = (d1, d2) if d1 < d2 else (d2, d1)
    days = 0
    d = start
    while d < end:
        if d.weekday() < 5:
            days += 1
        d += dt.timedelta(days=1)
    return days

# ---------------- Outlook helpers -----------------
def _get_outlook_folder_by_path(root_ns, path_spec: str):
    parts = [p for p in path_spec.replace("/", "\\").split("\\") if p]
    if not parts:
        raise ValueError("Empty Outlook folder path")
    try:
        cur = root_ns.Folders.Item(parts[0])
    except Exception as e:
        raise RuntimeError(f"Mailbox not found: {parts[0]}") from e
    built = [parts[0]]
    for p in parts[1:]:
        built.append(p)
        try:
            cur = cur.Folders.Item(p)
        except Exception as e:
            raise RuntimeError(f"Outlook subfolder not found: {'\\\\'.join(built)}") from e
    return cur

def outlook_pull_latest_attachment(folder_path: str,
                                   subject_contains: str,
                                   attach_name_contains: str,
                                   save_dir: Path,
                                   extensions: tuple[str, ...] = (),
                                   days_back: int = 10):
    """
    Returns Path or None. Uses EnsureDispatch. No flags, just console output.
    """
    try:
        from win32com.client import gencache  # type: ignore
    except Exception:
        say_warn("Outlook COM not available (pywin32 missing).")
        return None

    save_dir.mkdir(parents=True, exist_ok=True)

    try:
        ns = gencache.EnsureDispatch("Outlook.Application").GetNamespace("MAPI")
        folder = _get_outlook_folder_by_path(ns, folder_path)
        items = folder.Items
        items.Sort("[ReceivedTime]", True)  # newest first
    except Exception as e:
        say_err(f"Failed to access Outlook folder '{folder_path}': {e}")
        return None

    subj_key = (subject_contains or "").lower()
    name_key = (attach_name_contains or "").lower()
    from_dt = (dt.datetime.now() - dt.timedelta(days=days_back))

    try:
        for itm in items:
            try:
                rt = getattr(itm, "ReceivedTime", None)
                if rt and rt < from_dt:
                    break
                subj = (getattr(itm, "Subject", "") or "")
                if subj_key and subj_key not in subj.lower():
                    continue
                atts = getattr(itm, "Attachments", None)
                if not atts or atts.Count == 0:
                    continue
                for i in range(1, atts.Count + 1):
                    att = atts.Item(i)
                    fname = str(att.FileName or "")
                    low = fname.lower()
                    if name_key and name_key not in low:
                        continue
                    if extensions and not any(low.endswith(ext) for ext in extensions):
                        continue
                    dest = save_dir / fname
                    att.SaveAsFile(str(dest))
                    say_info(f"Pulled from Outlook: {dest}")
                    return dest
            except Exception:
                continue
    except Exception as e:
        say_err(f"Error iterating Outlook items: {e}")

    say_info("No matching Outlook attachment found in the search window.")
    return None

# ---------------- Teams / Email alerts -------------
def send_teams_alert(webhook_url: str, title: str, lines: list[str]) -> bool:
    text = "**" + title + "**\n\n" + "\n".join(f"- {ln}" for ln in lines)
    payload = {"text": text}
    try:
        import json
        try:
            import requests  # type: ignore
            resp = requests.post(webhook_url, json=payload, timeout=10)
            resp.raise_for_status()
            say_alert("Teams alert sent.")
            return True
        except ImportError:
            from urllib.request import Request, urlopen
            req = Request(
                webhook_url,
                data=json.dumps(payload).encode("utf-8"),
                headers={"Content-Type": "application/json"},
            )
            with urlopen(req, timeout=10) as r:
                _ = r.read()
            say_alert("Teams alert sent (urllib).")
            return True
    except Exception as e:
        say_warn(f"Teams alert failed: {e}")
        return False

def send_outlook_email(to_addr: str, subject: str, body_html: str) -> bool:
    try:
        from win32com.client import gencache  # type: ignore
        ol = gencache.EnsureDispatch("Outlook.Application")
        mail = ol.CreateItem(0)
        mail.To = to_addr
        mail.Subject = subject
        mail.HTMLBody = body_html
        mail.Send()
        say_alert(f"Outlook email sent to {to_addr}.")
        return True
    except Exception as e:
        say_warn(f"Outlook email failed: {e}")
        return False

# ------------- XLSX: STOCK HOLDING extractor -------------
def _is_statement_date_label(s: str) -> bool:
    if s is None:
        return False
    s = str(s).strip().lower().rstrip(":")
    return s == "statement date"

def extract_all_statement_dates_from_stock_holding(xlsx_path: Path):
    try:
        import openpyxl
    except Exception as e:
        raise RuntimeError("openpyxl required: pip install openpyxl") from e

    if not xlsx_path.exists():
        raise FileNotFoundError(f"Missing: {xlsx_path}")

    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)
    if "Stock Holding" not in wb.sheetnames:
        raise RuntimeError("Worksheet 'Stock Holding' not found in STOCK HOLDING.xlsx")

    ws = wb["Stock Holding"]
    dates = []
    merged_map = {}
    for rng in ws.merged_cells.ranges:
        min_row, min_col, max_row, max_col = rng.min_row, rng.min_col, rng.max_row, rng.max_col
        top_left = ws.cell(min_row, min_col).value
        for r in range(min_row, max_row + 1):
            for c in range(min_col, max_col + 1):
                merged_map[(r, c)] = top_left

    for row in ws.iter_rows(min_row=1, max_row=300, min_col=1, max_col=50):
        for cell in row:
            raw = merged_map.get((cell.row, cell.column), cell.value)
            if _is_statement_date_label(raw):
                right_raw = merged_map.get(
                    (cell.row, cell.column + 1),
                    ws.cell(row=cell.row, column=cell.column + 1).value
                )
                if isinstance(right_raw, dt.datetime):
                    dates.append(right_raw.date())
                elif isinstance(right_raw, dt.date):
                    dates.append(right_raw)
                else:
                    d = parse_date_token(str(right_raw))
                    if d:
                        dates.append(d)
    return dates

# ------------- CSV: ALL ENTITIES extractor ---------------
def _sniff_csv_dialect(sample_text: str):
    try:
        return csv.Sniffer().sniff(sample_text)
    except Exception:
        return csv.excel

def extract_all_statement_dates_from_recon_csv(csv_path: Path):
    if not csv_path.exists():
        raise FileNotFoundError(f"Missing: {csv_path}")

    dates = []
    head_text = csv_path.read_text(encoding="utf-8-sig", errors="ignore")[:8000]
    dialect = _sniff_csv_dialect(head_text)

    with csv_path.open("r", newline="", encoding="utf-8-sig", errors="ignore") as f:
        rdr = csv.DictReader(f, dialect=dialect)
        if rdr.fieldnames:
            def norm(h): return re.sub(r"\s+", " ", h or "").strip().lower()
            header_map = {norm(h): h for h in rdr.fieldnames if h}
            target_key = None
            for k in ("statement date", "statement-date", "statementdate"):
                if k in header_map:
                    target_key = header_map[k]; break
            if target_key:
                for row in rdr:
                    d = parse_date_token(row.get(target_key, ""))
                    if d:
                        dates.append(d)

    if not dates:
        full_text = csv_path.read_text(encoding="utf-8-sig", errors="ignore")
        for m in re.finditer(r"(?i)statement\s*date[^0-9A-Za-z]+(\d{2}-[A-Za-z]{3}-\d{4})", full_text):
            d = parse_date_token(m.group(1))
            if d:
                dates.append(d)
        for m in re.finditer(r"(?i)statement\s*date[^\r\n]*\r?\n\s*(\d{2}-[A-Za-z]{3}-\d{4})", full_text):
            d = parse_date_token(m.group(1))
            if d:
                dates.append(d)

    return dates

# ------------------- AUDIT -------------------
def append_audit_row(audit_path: Path, row: dict):
    ensure_dir(audit_path.parent)
    write_header = not audit_path.exists()
    with audit_path.open("a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=[
            "timestamp_utc",
            "status",
            "stock_holding_path",
            "all_entities_path",
            "latest_stock_iso",
            "latest_csv_iso",
            "latest_stock_norm",
            "latest_csv_norm",
            "agree",
            "copied_csv",
            "copied_xlsx",
            "note"
        ])
        if write_header:
            w.writeheader()
        w.writerow(row)

# -------------------------- MAIN --------------------------
def main():
    banner()
    say_step("Initialising paths and options")

    stock_path = Path(STOCK_HOLDING_PATH)
    csv_path = Path(RECON_ALL_ENTITIES_PATH)
    ts = dt.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")

    # ----- Outlook fallback on missing files -----
    if not stock_path.exists() and ENABLE_OUTLOOK_FALLBACK_FILE1:
        say_warn(f"Missing File 1: {stock_path}. Trying Outlook fallback...")
        pulled = outlook_pull_latest_attachment(
            folder_path=OUTLOOK_FOLDER_FILE1,
            subject_contains=OUTLOOK_SUBJECT_CONTAINS_FILE1,
            attach_name_contains=ATTACH_NAME_CONTAINS_FILE1,
            save_dir=stock_path.parent,
            extensions=(".xlsx",),
            days_back=OUTLOOK_SEARCH_WINDOW_DAYS
        )
        if pulled:
            stock_path = Path(pulled)

    if not csv_path.exists() and ENABLE_OUTLOOK_FALLBACK_FILE2:
        say_warn(f"Missing File 2: {csv_path}. Trying Outlook fallback...")
        pulled = outlook_pull_latest_attachment(
            folder_path=OUTLOOK_FOLDER_FILE2,
            subject_contains=OUTLOOK_SUBJECT_CONTAINS_FILE2,
            attach_name_contains=ATTACH_NAME_CONTAINS_FILE2,
            save_dir=csv_path.parent,
            extensions=(".csv",),
            days_back=OUTLOOK_SEARCH_WINDOW_DAYS
        )
        if pulled:
            csv_path = Path(pulled)

    # ----- Missing file handling (after fallback) -----
    if not stock_path.exists():
        say_err(f"Missing file: {stock_path}")
        append_audit_row(Path(AUDIT_LOG_PATH), {
            "timestamp_utc": dt.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
            "status": "ERROR_MISSING_FILE1",
            "stock_holding_path": str(stock_path),
            "all_entities_path": str(csv_path),
            "latest_stock_iso": "",
            "latest_csv_iso": "",
            "latest_stock_norm": "",
            "latest_csv_norm": "",
            "agree": "n/a",
            "copied_csv": "n/a",
            "copied_xlsx": "n/a",
            "note": "File 1 missing"
        })
        sys.exit(2)

    if not csv_path.exists():
        say_err(f"Missing file: {csv_path}")
        append_audit_row(Path(AUDIT_LOG_PATH), {
            "timestamp_utc": dt.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
            "status": "ERROR_MISSING_FILE2",
            "stock_holding_path": str(stock_path),
            "all_entities_path": str(csv_path),
            "latest_stock_iso": "",
            "latest_csv_iso": "",
            "latest_stock_norm": "",
            "latest_csv_norm": "",
            "agree": "n/a",
            "copied_csv": "n/a",
            "copied_xlsx": "n/a",
            "note": "File 2 missing"
        })
        sys.exit(2)

    # ----- Extract ALL dates -----
    say_step("Extracting 'Statement Date' values from both files")
    try:
        dates_stock = extract_all_statement_dates_from_stock_holding(stock_path)
    except Exception as e:
        say_err(f"ERROR reading STOCK HOLDING.xlsx ‚Äî {e}")
        sys.exit(2)
    try:
        dates_csv = extract_all_statement_dates_from_recon_csv(csv_path)
    except Exception as e:
        say_err(f"ERROR reading Reconciliation - All Entities.csv ‚Äî {e}")
        sys.exit(2)

    if not dates_stock:
        say_err("No 'Statement Date' found in STOCK HOLDING.xlsx")
        sys.exit(2)
    if not dates_csv:
        say_err("No 'Statement Date' found in Reconciliation - All Entities.csv")
        sys.exit(2)

    latest_stock = max(dates_stock)
    latest_csv = max(dates_csv)
    latest_stock_norm = normalize_yyyy_mmm_dd(latest_stock)
    latest_csv_norm   = normalize_yyyy_mmm_dd(latest_csv)

    say_info(f"Latest STOCK HOLDING 'Statement Date' : {latest_stock_norm}  ({stock_path.name})")
    say_info(f"Latest All Entities 'Statement Date'  : {latest_csv_norm}    ({csv_path.name})")

    # ----- If File 1 looks stale, try Outlook refresh once -----
    age_bd = 0
    if latest_stock < latest_csv:
        age_bd = business_days_between(latest_stock, latest_csv)
        if age_bd > MAX_FILE1_AGE_BUSINESS_DAYS and ENABLE_OUTLOOK_FALLBACK_FILE1:
            say_warn(f"File 1 appears stale by {age_bd} business days ‚Äî attempting Outlook refresh...")
            pulled = outlook_pull_latest_attachment(
                folder_path=OUTLOOK_FOLDER_FILE1,
                subject_contains=OUTLOOK_SUBJECT_CONTAINS_FILE1,
                attach_name_contains=ATTACH_NAME_CONTAINS_FILE1,
                save_dir=stock_path.parent,
                extensions=(".xlsx",),
                days_back=OUTLOOK_SEARCH_WINDOW_DAYS
            )
            if pulled:
                new_dates = extract_all_statement_dates_from_stock_holding(Path(pulled))
                if new_dates:
                    latest_stock = max(new_dates)
                    latest_stock_norm = normalize_yyyy_mmm_dd(latest_stock)
                    age_bd = business_days_between(latest_stock, latest_csv)
                    say_info(f"Refreshed STOCK HOLDING from Outlook ‚Üí {latest_stock_norm}")

    # ----- STALE detection (after potential refresh) -----
    if latest_stock < latest_csv:
        age_bd = business_days_between(latest_stock, latest_csv)
        if age_bd > MAX_FILE1_AGE_BUSINESS_DAYS:
            say_err(f"File 1 (Stock Holding) STALE by {age_bd} business days "
                    f"({latest_stock_norm} vs {latest_csv_norm}).")

            # Optional alerts
            notes = []
            if USE_TEAMS_ALERT and TEAMS_WEBHOOK_URL:
                ok = send_teams_alert(
                    TEAMS_WEBHOOK_URL,
                    "Stock Rec ‚Äì STALE File 1",
                    [
                        f"File 1: {latest_stock_norm} ({stock_path.name})",
                        f"File 2: {latest_csv_norm} ({csv_path.name})",
                        f"Age (business days): {age_bd}"
                    ]
                )
                if not ok: notes.append("teams_alert_failed")
            if USE_OUTLOOK_EMAIL_ALERT:
                body_html = (f"<p><b>Stock Rec ‚Äì STALE File 1</b></p>"
                             f"<ul><li>File 1: <code>{latest_stock_norm}</code> ({stock_path.name})</li>"
                             f"<li>File 2: <code>{latest_csv_norm}</code> ({csv_path.name})</li>"
                             f"<li>Age (business days): {age_bd}</li></ul>")
                ok = send_outlook_email(EMAIL_TO, EMAIL_SUBJECT, body_html)
                if not ok: notes.append("email_alert_failed")

            append_audit_row(Path(AUDIT_LOG_PATH), {
                "timestamp_utc": dt.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "status": "ERROR_STALE_FILE1",
                "stock_holding_path": str(stock_path),
                "all_entities_path": str(csv_path),
                "latest_stock_iso": latest_stock.isoformat(),
                "latest_csv_iso": latest_csv.isoformat(),
                "latest_stock_norm": latest_stock_norm,
                "latest_csv_norm": latest_csv_norm,
                "agree": "false",
                "copied_csv": "false",
                "copied_xlsx": "false",
                "note": f"File1 stale by {age_bd} business days" + (("; " + "; ".join(notes)) if notes else "")
            })

            if SAVE_ON_MISMATCH:
                qdir = Path(UNC_BASE) / QUARANTINE_SUBFOLDER / ts
                ensure_dir(qdir)
                copy2(csv_path, qdir / csv_path.name)
                copy2(stock_path, qdir / stock_path.name)
                say_warn(f"Quarantined copies saved to: {qdir}")

            sys.exit(3)

    # ----- MISMATCH (dates unequal but not stale per threshold) -----
    agree = (latest_stock_norm == latest_csv_norm)
    if not agree:
        say_err("Dates differ (not hitting stale threshold).")

        notes = []
        if USE_TEAMS_ALERT and TEAMS_WEBHOOK_URL:
            ok = send_teams_alert(
                TEAMS_WEBHOOK_URL,
                "Stock Rec ‚Äì Date Mismatch",
                [
                    f"File 1: {latest_stock_norm} ({stock_path.name})",
                    f"File 2: {latest_csv_norm} ({csv_path.name})",
                    f"Age (business days): {age_bd}"
                ]
            )
            if not ok: notes.append("teams_alert_failed")
        if USE_OUTLOOK_EMAIL_ALERT:
            body_html = (f"<p><b>Stock Rec ‚Äì Date Mismatch</b></p>"
                         f"<ul><li>File 1: <code>{latest_stock_norm}</code> ({stock_path.name})</li>"
                         f"<li>File 2: <code>{latest_csv_norm}</code> ({csv_path.name})</li>"
                         f"<li>Age (business days): {age_bd}</li></ul>")
            ok = send_outlook_email(EMAIL_TO, EMAIL_SUBJECT, body_html)
            if not ok: notes.append("email_alert_failed")

        append_audit_row(Path(AUDIT_LOG_PATH), {
            "timestamp_utc": dt.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
            "status": "MISMATCH",
            "stock_holding_path": str(stock_path),
            "all_entities_path": str(csv_path),
            "latest_stock_iso": latest_stock.isoformat(),
            "latest_csv_iso": latest_csv.isoformat(),
            "latest_stock_norm": latest_stock_norm,
            "latest_csv_norm": latest_csv_norm,
            "agree": "false",
            "copied_csv": "false",
            "copied_xlsx": "false",
            "note": "Dates unequal (not stale)" + (("; " + "; ".join(notes)) if notes else "")
        })

        if SAVE_ON_MISMATCH:
            qdir = Path(UNC_BASE) / QUARANTINE_SUBFOLDER / ts
            ensure_dir(qdir)
            copy2(csv_path, qdir / csv_path.name)
            copy2(stock_path, qdir / stock_path.name)
            say_warn(f"Quarantined copies saved to: {qdir}")

        sys.exit(3)

    # ----- AGREEMENT: Save to UNC with renamed outputs (no overwrite) -----
    say_ok("Dates agree.")
    copied_csv = False
    copied_xlsx = False

    if SAVE_ON_AGREE:
        say_step("Saving agreed files to UNC (skip if already present)")
        target_dir = build_unc_target(UNC_BASE, latest_stock)
        ensure_dir(target_dir)

        out_csv_name  = dated_filename(Path(RECON_ALL_ENTITIES_PATH), latest_stock)
        out_xlsx_name = dated_filename(Path(STOCK_HOLDING_PATH),      latest_stock)

        csv_dest  = target_dir / out_csv_name
        xlsx_dest = target_dir / out_xlsx_name

        copied_csv  = copy_if_absent(csv_path,  csv_dest)
        copied_xlsx = copy_if_absent(stock_path, xlsx_dest)

    append_audit_row(Path(AUDIT_LOG_PATH), {
        "timestamp_utc": dt.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
        "status": "OK",
        "stock_holding_path": str(stock_path),
        "all_entities_path": str(csv_path),
        "latest_stock_iso": latest_stock.isoformat(),
        "latest_csv_iso": latest_csv.isoformat(),
        "latest_stock_norm": latest_stock_norm,
        "latest_csv_norm": latest_csv_norm,
        "agree": "true",
        "copied_csv": "true" if copied_csv else "false",
        "copied_xlsx": "true" if copied_xlsx else "false",
        "note": "Saved to UNC (skips indicate prior presence)"
    })

    sys.exit(0)


if __name__ == "__main__":
    main()
